{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leo14993/analise-ligas-heas/blob/main/Analise_HEAs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-RQNuQCzdt1"
      },
      "source": [
        "## 1. Importando as dependencias do projeto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frBKlh347gWY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "#selecao e separação de dados\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, \n",
        "    cross_val_score, \n",
        "    cross_val_predict\n",
        "  )\n",
        "\n",
        "#pre processamento de dados\n",
        "from sklearn.preprocessing import (\n",
        "    OneHotEncoder, \n",
        "    LabelEncoder, \n",
        "    OrdinalEncoder, \n",
        "    StandardScaler\n",
        "  )\n",
        "\n",
        "# avaliação resultados\n",
        "from sklearn.metrics import (\n",
        "    roc_curve,\n",
        "    accuracy_score, \n",
        "    confusion_matrix,\n",
        "    multilabel_confusion_matrix,\n",
        "    classification_report,\n",
        "    ConfusionMatrixDisplay,\n",
        "    RocCurveDisplay\n",
        "  )\n",
        "\n",
        "#modelos\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "#sobreamostragem\n",
        "from imblearn.over_sampling import (\n",
        "    SMOTE, \n",
        "    ADASYN,\n",
        "    BorderlineSMOTE, \n",
        "    KMeansSMOTE, \n",
        "    SVMSMOTE\n",
        "  )\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ! pip install yellowbrick\n",
        "# from yellowbrick.classifier import ROCAUC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNLg-fSzi-a"
      },
      "source": [
        "## 2. Importando os dados e removendo colunas não utilizadas, e removendo linhas duplicadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8Yj4dSgc632"
      },
      "outputs": [],
      "source": [
        "# caminho google colab\n",
        "df = pd.read_csv('/content/drive/MyDrive/Documentos/TCC/HEAs_Machine_Learning/dados/df_final2.csv', error_bad_lines=False, sep=';')\n",
        "\n",
        "# removendo os dados de componentes quimicos para gerar arquivo de analise\n",
        "# apenas considerando as fases e outras variaveis\n",
        "# df = df.drop(['Al','Co', 'Fe','Ni',\t'Si','Cr','Mn','Nb',\n",
        "#               'Mo','Ti','Cu','V','Zr','Ta','Hf','W' ],axis=1)\n",
        "\n",
        "df.drop(['PROPERTY: Type of test', 'PROPERTY: YS (MPa)' , 'Alloy name', 'index'],axis=1, inplace=True)\n",
        "# df = df.drop(['PROPERTY: Type of test', 'PROPERTY: YS (MPa)' ],axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WSZxsStzs7r"
      },
      "source": [
        "* Etapa de analise de dados(opcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhOPeP11xIIy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu9elKkpPCM-"
      },
      "outputs": [],
      "source": [
        "# jupyter\n",
        "# !pip install pandas-profilling\n",
        "\n",
        "# colab\n",
        "\n",
        "#antes de executar o profile report é necessario reiniciar o ambiente de execução,\n",
        "# instalar o pandas profiling para verificar a ausencia de alguma dependencia\n",
        "# reiniciar novamente e importar \n",
        "# # ! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n",
        "# from pandas_profiling import ProfileReport\n",
        "\n",
        "# # prof = ProfileReport(df)\n",
        "# # prof.to_file(output_file='analise_dados_inicial.html')\n",
        "\n",
        "# prof = ProfileReport(df_droped_duplicates)\n",
        "# prof.to_file(output_file='analise_dados_inicial_sem_duplicados.html')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRY_eUQKpG38"
      },
      "source": [
        "## 3. Conversão das variáveis categóricas em numeros inteiros / trocando valores nulos por zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e4wZhfK7mdk"
      },
      "outputs": [],
      "source": [
        "# Tornando variaveis categóricas em numeros ordinais\n",
        "\n",
        "processing_method_ord_enc = \\\n",
        "  OrdinalEncoder().fit(df[['PROPERTY: Processing method']])\n",
        "#   LabelEncoder().fit(df[['PROPERTY: Processing method']])\n",
        "\n",
        "\n",
        "# alloy_name_ord_enc = OrdinalEncoder().fit(df[['Alloy name']])\n",
        "microstructure_ord_enc = \\\n",
        "  OrdinalEncoder().fit(df[['PROPERTY: Microstructure']])\n",
        "  # LabelEncoder().fit(df[['PROPERTY: Microstructure']])\n",
        "  \n",
        "\n",
        "\n",
        "df['PROPERTY: Processing method'] = \\\n",
        "  processing_method_ord_enc.transform(df[['PROPERTY: Processing method']])\n",
        "# df['Alloy name'] = alloy_name_ord_enc.transform(df[['Alloy name']])\n",
        "df['PROPERTY: Microstructure'] = \\\n",
        "  microstructure_ord_enc.transform(df[['PROPERTY: Microstructure']])\n",
        "\n",
        "a = microstructure_ord_enc.inverse_transform(df[['PROPERTY: Microstructure']])\n",
        "\n",
        "\n",
        "df.fillna(0,inplace=True)\n",
        "\n",
        "df_droped_duplicates = df.drop_duplicates()\n",
        "df_droped_duplicates.reset_index(inplace=True)\n",
        "\n",
        "df_droped_duplicates.drop(['index'],axis=1, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5ihPvc4mbpE"
      },
      "source": [
        "## 3.1 Função para plotar matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT2j2LkIX7i6"
      },
      "outputs": [],
      "source": [
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=None,\n",
        "                          cmap='Blues',\n",
        "                          title=None,\n",
        "                          file_name=None,\n",
        "                          show_accuracy=False):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                   \n",
        "    title:         Title for the heatmap. Default is None.\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    stats_text = \"\"\n",
        "    \n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if show_accuracy:\n",
        "          if len(cf)==2:\n",
        "              #Metrics for Binary Confusion Matrices\n",
        "              precision = cf[1,1] / sum(cf[:,1])\n",
        "              recall    = cf[1,1] / sum(cf[1,:])\n",
        "              f1_score  = 2*precision*recall / (precision + recall)\n",
        "              stats_text = \"\\n\\nAcurácia={:0.3f}\\nPrecisão={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
        "                  accuracy,precision,recall,f1_score)\n",
        "          else:\n",
        "              stats_text = \"\\n\\nAcurácia={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "    # --------------\n",
        "    # cf_sum = np.sum(cf, axis=1, keepdims=True)\n",
        "    # cf_perc = cf / cf_sum.astype(float) * 100\n",
        "    # annot = np.empty_like(cf).astype(str)\n",
        "    # nrows, ncols = cf.shape\n",
        "    # for i in range(nrows):\n",
        "    #     for j in range(ncols):\n",
        "    #         c = cf[i, j]\n",
        "    #         p = cf_perc[i, j]\n",
        "    #         if i == j:\n",
        "    #             s = cf_sum[i]\n",
        "    #             annot[i, j] = '%.2f%%\\n%d/%d' % (p, c, s)\n",
        "    #         #elif c == 0:\n",
        "    #         #    annot[i, j] = ''\n",
        "    #         else:\n",
        "    #             annot[i, j] = '%.2f%%\\n%d' % (p, c)\n",
        "    # --------------------\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    image_plot = sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "    \n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('Microestruturas reais')\n",
        "        plt.xlabel('Microestruturas previstas' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "    \n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "    if file_name:\n",
        "      plt.savefig(f'{file_name}.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eImIFZsss4fb"
      },
      "outputs": [],
      "source": [
        "def cm_analysis(y_true, y_pred, filename, labels, classes, ymap=None, figsize=(17,17), cmap=\"Blues\"):\n",
        "    \"\"\"\n",
        "    Generate matrix plot of confusion matrix with pretty annotations.\n",
        "    The plot image is saved to disk.\n",
        "    args: \n",
        "      y_true:    true label of the data, with shape (nsamples,)\n",
        "      y_pred:    prediction of the data, with shape (nsamples,)\n",
        "      filename:  filename of figure file to save\n",
        "      labels:    string array, name the order of class labels in the confusion matrix.\n",
        "                 use `clf.classes_` if using scikit-learn models.\n",
        "                 with shape (nclass,).\n",
        "      classes:   aliases for the labels. String array to be shown in the cm plot.\n",
        "      ymap:      dict: any -> string, length == nclass.\n",
        "                 if not None, map the labels & ys to more understandable strings.\n",
        "                 Caution: original y_true, y_pred and labels must align.\n",
        "      figsize:   the size of the figure plotted.\n",
        "    \"\"\"\n",
        "    sns.set(font_scale=1.1)\n",
        "\n",
        "    if ymap is not None:\n",
        "        y_pred = [ymap[yi] for yi in y_pred]\n",
        "        y_true = [ymap[yi] for yi in y_true]\n",
        "        labels = [ymap[yi] for yi in labels]\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "    cm_perc = cm / cm_sum.astype(float) * 100\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            c = cm[i, j]\n",
        "            p = cm_perc[i, j]\n",
        "            if i == j:\n",
        "                s = cm_sum[i]\n",
        "                annot[i, j] = '%.2f%%' % (p)\n",
        "                # annot[i, j] = '%.2f%%\\n%d/%d' % (p, c, s)\n",
        "            #elif c == 0:\n",
        "            #    annot[i, j] = ''\n",
        "            else:\n",
        "                annot[i, j] = '%.2f%%' % (p)\n",
        "                # annot[i, j] = '%.2f%%\\n%d' % (p, c)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels, normalize='true')\n",
        "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    cm = cm * 100\n",
        "    cm.index.name = 'Microestruturas reais'\n",
        "    cm.columns.name = 'Microestruturas previstas'\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    \n",
        "    # plt.yticks(va='center')\n",
        "\n",
        "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, xticklabels=classes, cbar=True, \n",
        "                cbar_kws={'format':PercentFormatter()}, \n",
        "                yticklabels=classes, cmap=cmap)\n",
        "    plt.savefig(filename,  \n",
        "                bbox_inches='tight'\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV0GJzrNpNLU"
      },
      "source": [
        "## 4. Separar o conjunto das variaveis e o conjunto dos alvos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEBdzCLsbnZh"
      },
      "outputs": [],
      "source": [
        "\n",
        "#com duplicados\n",
        "microstructure = df[['PROPERTY: Microstructure']]\n",
        "properties = df[df.columns.difference(['PROPERTY: Microstructure'])]\n",
        "\n",
        "\n",
        "#sem duplicados\n",
        "microstructure_droped_duplicates = \\\n",
        "  df_droped_duplicates[['PROPERTY: Microstructure']]\n",
        "properties_droped_duplicates = \\\n",
        "  df_droped_duplicates[df_droped_duplicates.columns.difference(\n",
        "      ['PROPERTY: Microstructure']\n",
        "  )]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    properties,\n",
        "    microstructure,\n",
        "    test_size = 0.3,\n",
        "    random_state = 99   \n",
        "    )\n",
        "\n",
        "x_train_droped_duplicates, x_test_droped_duplicates, \\\n",
        "y_train_droped_duplicates, y_test_droped_duplicates = train_test_split(\n",
        "    properties_droped_duplicates,\n",
        "    microstructure_droped_duplicates,\n",
        "    test_size = 0.3,\n",
        "    random_state = 99   \n",
        "    )\n",
        "\n",
        "\n",
        "# df_droped_duplicates.drop(['index'],axis=1, inplace=True)\n",
        "\n",
        "x_train_droped_duplicates.reset_index(inplace=True)\n",
        "x_train_droped_duplicates.drop(['index',],axis=1, inplace=True)\n",
        "x_test_droped_duplicates.reset_index(inplace=True)\n",
        "x_test_droped_duplicates.drop(['index',],axis=1, inplace=True)\n",
        "y_train_droped_duplicates.reset_index(inplace=True)\n",
        "y_train_droped_duplicates.drop(['index'],axis=1, inplace=True)\n",
        "y_test_droped_duplicates.reset_index(inplace=True)\n",
        "y_test_droped_duplicates.drop(['index'],axis=1, inplace=True)\n",
        "\n",
        "\n",
        "k_folds = 10\n",
        "\n",
        "n_validations = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCCAy0rXDHmY"
      },
      "source": [
        "## 5. Comparando resultados de dados duplicados ou não duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekqPybd0EcVn"
      },
      "source": [
        "###  5.1. Com duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr7xCIG8z3-Q"
      },
      "outputs": [],
      "source": [
        "default_forest = RandomForestClassifier(random_state=54)\n",
        "\n",
        "# microstructures = ['BCC','BCC ++','BCC B2','FCC','FCC ++','FCC BCC','OTHER']\n",
        "microstructures = ['CCC','CCC ++','CCC B2','CFC','CFC ++','CFC CCC','OUTROS']\n",
        "\n",
        "is_float = lambda x : x.replace('.','',1).isdigit()\n",
        "\n",
        "inverse_transform_microstructure = lambda x : microstructure_ord_enc.inverse_transform([[float(x)]])[0][0]\n",
        "\n",
        "categorical_key = lambda x : inverse_transform_microstructure(x) if is_float(x) else x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX5hedwjDGrd",
        "outputId": "b8f265c6-bdca-4b8b-b075-b5b116c2422d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "media f1 scores:  0.5708930054786975\n"
          ]
        }
      ],
      "source": [
        "#1. predition with cross validation\n",
        "microstructure_pred = cross_val_predict(\n",
        "    default_forest, \n",
        "    properties, \n",
        "    microstructure.values.reshape(-1,), \n",
        "    cv=k_folds\n",
        "  )\n",
        "\n",
        "#2. fitting model with all data\n",
        "default_forest_fit = default_forest.fit(\n",
        "    properties, \n",
        "    microstructure.values.reshape(-1,)\n",
        "  )\n",
        "\n",
        "#3. Confusion matrix with Diagonal \n",
        "confusion_matrix_microstructure = confusion_matrix(\n",
        "      microstructure, \n",
        "      microstructure_pred\n",
        "  )\n",
        "\n",
        "#4. confusion matrix with TP, TN, FP, FN\n",
        "multilabel_confusion_matrix_microstructure = \\\n",
        "  multilabel_confusion_matrix(microstructure, microstructure_pred)\n",
        "\n",
        "#5. get classification report \n",
        "# with the report, we have a bigger picture, with precision and recall for each class\n",
        "clf_report = classification_report(\n",
        "    microstructure, \n",
        "    microstructure_pred, \n",
        "    output_dict=True\n",
        "  ) \n",
        "\n",
        "f1_scores = []\n",
        "for i in clf_report:\n",
        "  if is_float(i):\n",
        "    f1_scores.append(clf_report[i]['f1-score'])\n",
        "print('media f1 scores: ',mean(f1_scores))\n",
        "\n",
        "# print(clf_report)\n",
        "#6. applyting name of microstructures on axis\n",
        "clf_report = {categorical_key(k):v for (k,v) in clf_report.items()}\n",
        "\n",
        "#7. creating dataframe\n",
        "df_classification_report = pd.DataFrame(clf_report).transpose()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfdUm-sSEvEI"
      },
      "source": [
        "###  5.1. Sem duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPPzSZBOEbc6",
        "outputId": "9cdf874d-88f3-443c-daaf-765847b90dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "media f1 scores:  0.5394325700973225\n"
          ]
        }
      ],
      "source": [
        "#1. predition with cross validation\n",
        "microstructure_pred_droped_duplicates = cross_val_predict(\n",
        "    default_forest, \n",
        "    properties_droped_duplicates, \n",
        "    microstructure_droped_duplicates.values.reshape(-1,), \n",
        "    cv=k_folds\n",
        "  )\n",
        "\n",
        "#2. fitting model with duplicates removed\n",
        "microstructure_confusion_matrix_droped_duplicates = \\\n",
        "  multilabel_confusion_matrix(\n",
        "      microstructure_droped_duplicates, \n",
        "      microstructure_pred_droped_duplicates\n",
        "  )\n",
        "\n",
        "#3. Confusion matrix with Diagonal \n",
        "confusion_matrix_microstructure_droped_duplicates = confusion_matrix(\n",
        "      microstructure_droped_duplicates, \n",
        "      microstructure_pred_droped_duplicates\n",
        "  )\n",
        "\n",
        "#4. confusion matrix with TP, TN, FP, FN\n",
        "multilabel_confusion_matrix_microstructure_droped_duplicates = \\\n",
        "  multilabel_confusion_matrix(\n",
        "      microstructure_droped_duplicates, \n",
        "      microstructure_pred_droped_duplicates\n",
        "    )\n",
        "\n",
        "#5. get classification report \n",
        "clf_report_droped_duplicates = classification_report(\n",
        "    microstructure_droped_duplicates, \n",
        "    microstructure_pred_droped_duplicates, \n",
        "    output_dict=True\n",
        "  )\n",
        "\n",
        "f1_scores = []\n",
        "for i in clf_report_droped_duplicates:\n",
        "  if is_float(i):\n",
        "    f1_scores.append(clf_report_droped_duplicates[i]['f1-score'])\n",
        "print('media f1 scores: ',mean(f1_scores))\n",
        "\n",
        "#6. applyting name of microstructures on axis\n",
        "clf_report_droped_duplicates = {categorical_key(k):v for (k,v) in clf_report_droped_duplicates.items()}\n",
        "\n",
        "#7. creating dataframe\n",
        "df_classification_report_droped_duplicates = pd.DataFrame(clf_report_droped_duplicates).transpose()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAwlwWVZ_kb4"
      },
      "source": [
        "### 5.3 Comparando dados de conjunto completo e sem duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7umTvu8k1lQ"
      },
      "source": [
        "Conjunto de Dados Completo\n",
        "- relatório com métricas\n",
        "- Matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Styhvs6WBNxK",
        "outputId": "cb743e31-a51a-4cf3-d17e-35263f95b39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " relatorio de dados com duplicados, n= (589, 27)\n",
            "\n",
            "               precision    recall  f1-score    support\n",
            "BCC            0.750000  0.740260  0.745098  154.00000\n",
            "BCC ++         0.507042  0.418605  0.458599   86.00000\n",
            "BCC B2         0.428571  0.571429  0.489796   42.00000\n",
            "FCC            0.711538  0.755102  0.732673  147.00000\n",
            "FCC ++         0.596774  0.445783  0.510345   83.00000\n",
            "FCC BCC        0.500000  0.600000  0.545455   45.00000\n",
            "OTHER          0.473684  0.562500  0.514286   32.00000\n",
            "accuracy       0.623090  0.623090  0.623090    0.62309\n",
            "macro avg      0.566802  0.584811  0.570893  589.00000\n",
            "weighted avg   0.626302  0.623090  0.621087  589.00000 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('\\n relatorio de dados com duplicados, n=', \n",
        "      properties.shape)\n",
        "print('\\n', df_classification_report, '\\n')\n",
        "make_confusion_matrix(confusion_matrix_microstructure, \n",
        "                      figsize=(10,8), \n",
        "                      categories=microstructures,\n",
        "                      cmap='Reds',\n",
        "                      title='Dados completos')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x09sdFDBlFGA"
      },
      "source": [
        "Dados sem duplicados\n",
        "- relatório com métricas\n",
        "- Matriz de confusão\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXjhnk36kwzk",
        "outputId": "a2d60c5c-1e41-4a12-b10b-d8f8e43db907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " relatorio de dados sem duplicados, n= (382, 27)\n",
            "\n",
            "               precision    recall  f1-score    support\n",
            "BCC            0.730435  0.785047  0.756757  107.00000\n",
            "BCC ++         0.541667  0.393939  0.456140   66.00000\n",
            "BCC B2         0.447368  0.548387  0.492754   31.00000\n",
            "FCC            0.520000  0.629032  0.569343   62.00000\n",
            "FCC ++         0.581395  0.471698  0.520833   53.00000\n",
            "FCC BCC        0.534884  0.547619  0.541176   42.00000\n",
            "OTHER          0.450000  0.428571  0.439024   21.00000\n",
            "accuracy       0.583770  0.583770  0.583770    0.58377\n",
            "macro avg      0.543678  0.543471  0.539433  382.00000\n",
            "weighted avg   0.583100  0.583770  0.579073  382.00000 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('\\n relatorio de dados sem duplicados, n=', \n",
        "      properties_droped_duplicates.shape)\n",
        "print('\\n', df_classification_report_droped_duplicates, '\\n')\n",
        "make_confusion_matrix(confusion_matrix_microstructure_droped_duplicates, \n",
        "                      figsize=(10,8), \n",
        "                      categories=microstructures,\n",
        "                      cmap='Reds',\n",
        "                      title='Dados duplicados removidos')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNOeEIXTpVUr"
      },
      "source": [
        "## 6. Normalização dos dados\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> As colunas que possuem variaveis categóricas convertidas em numéricas, não precisam ser normalizadas, umas vez que que os valores são equidistantes. \n",
        "\n",
        "> Colunas dos elementos quimicos possuem seus valores em porcentagem, neste caso também não podem ser normalizados, quando normalizados perdem seu real significado e valor.\n",
        "\n",
        "> Apenas os dados sem duplicados serão normalizados, uma vez que já foi feita uma comparação no bloco anterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_Lz--EQpU8A"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------------------------\n",
        "# Normalizando os dados\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "# properties_to_not_normalize = properties_droped_duplicates[['PROPERTY: Processing method',\n",
        "#   'Al','Co', 'Fe','Ni',\t'Si','Cr','Mn','Nb',\n",
        "#   'Mo','Ti','Cu','V','Zr','Ta','Hf','W']]\n",
        "\n",
        "# columns_to_normalize = properties_droped_duplicates.columns.difference([\n",
        "#   'PROPERTY: Processing method',\n",
        "#   'Al','Co', 'Fe','Ni',\t'Si','Cr','Mn','Nb',\n",
        "#   'Mo','Ti','Cu','V','Zr','Ta','Hf','W'])\n",
        "\n",
        "properties_to_not_normalize = properties_droped_duplicates[[\n",
        "  'Al','Co', 'Fe','Ni',\t'Si','Cr','Mn','Nb',\n",
        "  'Mo','Ti','Cu','V','Zr','Ta','Hf','W']]\n",
        "\n",
        "columns_to_normalize = properties_droped_duplicates.columns.difference([\n",
        "  \n",
        "  'Al','Co', 'Fe','Ni',\t'Si','Cr','Mn','Nb',\n",
        "  'Mo','Ti','Cu','V','Zr','Ta','Hf','W'])\n",
        "\n",
        "properties_to_normalize = properties_droped_duplicates[columns_to_normalize]\n",
        "\n",
        "# std_properties = StandardScaler().fit(properties_to_normalize)\n",
        "\n",
        "# normalized_properties = std_properties.transform(properties_to_normalize)\n",
        "\n",
        "# properties_droped_duplicates_normalized = \\\n",
        "#   pd.concat([pd.DataFrame(normalized_properties, columns=columns_to_normalize),\n",
        "#             properties_to_not_normalize], \n",
        "#             axis=1\n",
        "#   )\n",
        "\n",
        "properties_droped_duplicates_normalized = properties_to_not_normalize\n",
        "\n",
        "df_properties_droped_duplicates_normalized = pd.concat(\n",
        "    (properties_droped_duplicates_normalized,\n",
        "    microstructure_droped_duplicates),\n",
        "    axis=1\n",
        "    )\n",
        "\n",
        "x_train_normalized, x_test_normalized, y_train_normalized, y_test_normalized = \\\n",
        "  train_test_split(\n",
        "    properties_droped_duplicates_normalized,\n",
        "    microstructure_droped_duplicates,\n",
        "    test_size = 0.3,\n",
        "    random_state = 99   \n",
        "    )\n",
        "\n",
        "\n",
        "# df_droped_duplicates.drop(['index'],axis=1, inplace=True)\n",
        "\n",
        "x_train_normalized.reset_index(inplace=True)\n",
        "x_train_normalized.drop(['index',],axis=1, inplace=True)\n",
        "x_test_normalized.reset_index(inplace=True)\n",
        "x_test_normalized.drop(['index',],axis=1, inplace=True)\n",
        "y_train_normalized.reset_index(inplace=True)\n",
        "y_train_normalized.drop(['index'],axis=1, inplace=True)\n",
        "y_test_normalized.reset_index(inplace=True)\n",
        "y_test_normalized.drop(['index'],axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQL6gPZRELeE"
      },
      "source": [
        "### 6.1 Verificando influência da normalização no conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LQ8OxW-EK7_",
        "outputId": "c6aee412-9f97-45e4-fbf5-bd02e10c3abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "media f1 scores:  0.5709053132731676\n"
          ]
        }
      ],
      "source": [
        "microstructure_pred_droped_duplicates_normalized = cross_val_predict(\n",
        "    default_forest, \n",
        "    properties_droped_duplicates_normalized, \n",
        "    microstructure_droped_duplicates.values.reshape(-1,), \n",
        "    cv=k_folds\n",
        "  )\n",
        "\n",
        "microstructure_confusion_matrix_droped_duplicates_normalized = \\\n",
        "  multilabel_confusion_matrix(\n",
        "      microstructure_droped_duplicates, \n",
        "      microstructure_pred_droped_duplicates_normalized\n",
        "  )\n",
        "\n",
        "clf_report_droped_duplicates_normalized = classification_report(\n",
        "    microstructure_droped_duplicates, \n",
        "    microstructure_pred_droped_duplicates_normalized,\n",
        "    output_dict=True\n",
        "  )\n",
        "\n",
        "f1_scores = []\n",
        "for i in clf_report_droped_duplicates_normalized:\n",
        "  if is_float(i):\n",
        "    f1_scores.append(clf_report_droped_duplicates_normalized[i]['f1-score'])\n",
        "print('media f1 scores: ',mean(f1_scores))\n",
        "\n",
        "\n",
        "# transform column index number to microstructure\n",
        "clf_report_droped_duplicates_normalized = {categorical_key(k):v for (k,v) in clf_report_droped_duplicates_normalized.items()}\n",
        "\n",
        "df_classification_report_droped_duplicates_normalized = pd.DataFrame(\n",
        "    clf_report_droped_duplicates_normalized\n",
        "  ).transpose()\n",
        "\n",
        "# df_classification_report.index.names = ['microstructure']\n",
        "\n",
        "cm_microstructure_droped_duplicates_normalized = confusion_matrix(\n",
        "      microstructure_droped_duplicates.values.reshape(-1,), \n",
        "      microstructure_pred_droped_duplicates_normalized\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mti61UhZHS5d"
      },
      "outputs": [],
      "source": [
        "# media f1 scores:  0.5394325700973225\n",
        "# media f1 scores norm :  0.5376535036701573"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErbylX2knN-o"
      },
      "source": [
        "### 6.2 Dados não normalizados\n",
        "- relatório com métricas\n",
        "- Matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYr2dT_XnNmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef94f0f-a9d0-4266-a7ea-512ecbd90142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " relatorio de dados não normalizados (382, 27)\n",
            "\n",
            "               precision    recall  f1-score    support\n",
            "BCC            0.730435  0.785047  0.756757  107.00000\n",
            "BCC ++         0.541667  0.393939  0.456140   66.00000\n",
            "BCC B2         0.447368  0.548387  0.492754   31.00000\n",
            "FCC            0.520000  0.629032  0.569343   62.00000\n",
            "FCC ++         0.581395  0.471698  0.520833   53.00000\n",
            "FCC BCC        0.534884  0.547619  0.541176   42.00000\n",
            "OTHER          0.450000  0.428571  0.439024   21.00000\n",
            "accuracy       0.583770  0.583770  0.583770    0.58377\n",
            "macro avg      0.543678  0.543471  0.539433  382.00000\n",
            "weighted avg   0.583100  0.583770  0.579073  382.00000 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('\\n relatorio de dados não normalizados', \n",
        "      properties_droped_duplicates.shape)\n",
        "print('\\n', df_classification_report_droped_duplicates, '\\n')\n",
        "make_confusion_matrix(confusion_matrix_microstructure_droped_duplicates, \n",
        "                      figsize=(10,8), \n",
        "                      categories=microstructures,\n",
        "                      cmap='Reds',\n",
        "                      title='Dados não normalizados')\n",
        "\n",
        "# cmd = ConfusionMatrixDisplay\n",
        "# ConfusionMatrixDisplay.from_predictions(microstructure_droped_duplicates,microstructure_pred_droped_duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DR3bwImnZdz"
      },
      "source": [
        "### 6.3 Dados normalizados\n",
        "- relatório com métricas\n",
        "- Matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4lZTdF7TleJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25cccc97-1be3-468d-e23e-f9481395993f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " relatorio de dados normalizados (382, 16)\n",
            "\n",
            "               precision    recall  f1-score     support\n",
            "BCC            0.713043  0.766355  0.738739  107.000000\n",
            "BCC ++         0.562500  0.409091  0.473684   66.000000\n",
            "BCC B2         0.636364  0.677419  0.656250   31.000000\n",
            "FCC            0.530120  0.709677  0.606897   62.000000\n",
            "FCC ++         0.650000  0.490566  0.559140   53.000000\n",
            "FCC BCC        0.500000  0.523810  0.511628   42.000000\n",
            "OTHER          0.473684  0.428571  0.450000   21.000000\n",
            "accuracy       0.604712  0.604712  0.604712    0.604712\n",
            "macro avg      0.580816  0.572213  0.570905  382.000000\n",
            "weighted avg   0.605793  0.604712  0.599090  382.000000 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('\\n relatorio de dados normalizados', \n",
        "      properties_droped_duplicates_normalized.shape)\n",
        "print('\\n', df_classification_report_droped_duplicates_normalized, '\\n')\n",
        "make_confusion_matrix(cm_microstructure_droped_duplicates_normalized, \n",
        "                      figsize=(10,8), \n",
        "                      categories=microstructures,\n",
        "                      cmap='Reds',\n",
        "                      title='Dados normalizados')\n",
        "\n",
        "# ConfusionMatrixDisplay.from_predictions(microstructure_droped_duplicates, microstructure_pred_droped_duplicates_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UToGCl2mvNNs"
      },
      "source": [
        "## Conclusão Normalização\n",
        "\n",
        "Ocorreu um leve redução da acurácia, porém com a normalização de dados, foi removida a possibilidade de enviesar os resultados por conta de outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKVPCnop4-Z7"
      },
      "source": [
        "## 7. Comparando diferentes modelos\n",
        "\n",
        "Nessa etapa são instanciados diversos modelos diferentes, e são comparados quais modelos performam melhor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4aLliFKIUL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ceebdf-1f27-4e8b-cecb-90471090d71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modelo                         acuracia                       f1 scores\n",
            "\n",
            " Model:  RandomForestClassifier\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.713043  0.766355  0.738739  107.000000\n",
            "BCC ++         0.562500  0.409091  0.473684   66.000000\n",
            "BCC B2         0.636364  0.677419  0.656250   31.000000\n",
            "FCC            0.530120  0.709677  0.606897   62.000000\n",
            "FCC ++         0.650000  0.490566  0.559140   53.000000\n",
            "FCC BCC        0.500000  0.523810  0.511628   42.000000\n",
            "OTHER          0.473684  0.428571  0.450000   21.000000\n",
            "accuracy       0.604712  0.604712  0.604712    0.604712\n",
            "macro avg      0.580816  0.572213  0.570905  382.000000\n",
            "weighted avg   0.605793  0.604712  0.599090  382.000000\n",
            "\n",
            " Model:  MLPClassifier\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.645390  0.850467  0.733871  107.000000\n",
            "BCC ++         0.608696  0.212121  0.314607   66.000000\n",
            "BCC B2         0.396226  0.677419  0.500000   31.000000\n",
            "FCC            0.350000  0.677419  0.461538   62.000000\n",
            "FCC ++         0.344828  0.188679  0.243902   53.000000\n",
            "FCC BCC        0.437500  0.166667  0.241379   42.000000\n",
            "OTHER          0.000000  0.000000  0.000000   21.000000\n",
            "accuracy       0.484293  0.484293  0.484293    0.484293\n",
            "macro avg      0.397520  0.396110  0.356471  382.000000\n",
            "weighted avg   0.470850  0.484293  0.435781  382.000000\n",
            "\n",
            " Model:  KNeighborsClassifier\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.622047  0.738318  0.675214  107.000000\n",
            "BCC ++         0.257143  0.136364  0.178218   66.000000\n",
            "BCC B2         0.355556  0.516129  0.421053   31.000000\n",
            "FCC            0.453488  0.629032  0.527027   62.000000\n",
            "FCC ++         0.485714  0.320755  0.386364   53.000000\n",
            "FCC BCC        0.457143  0.380952  0.415584   42.000000\n",
            "OTHER          0.263158  0.238095  0.250000   21.000000\n",
            "accuracy       0.473822  0.473822  0.473822    0.473822\n",
            "macro avg      0.413464  0.422806  0.407637  382.000000\n",
            "weighted avg   0.453241  0.473822  0.452671  382.000000\n",
            "\n",
            " Model:  SVC\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.741667  0.831776  0.784141  107.000000\n",
            "BCC ++         0.534884  0.348485  0.422018   66.000000\n",
            "BCC B2         0.437500  0.451613  0.444444   31.000000\n",
            "FCC            0.421053  0.774194  0.545455   62.000000\n",
            "FCC ++         0.333333  0.075472  0.123077   53.000000\n",
            "FCC BCC        0.500000  0.595238  0.543478   42.000000\n",
            "OTHER          0.454545  0.238095  0.312500   21.000000\n",
            "accuracy       0.544503  0.544503  0.544503    0.544503\n",
            "macro avg      0.488997  0.473553  0.453588  382.000000\n",
            "weighted avg   0.530211  0.544503  0.511162  382.000000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "forest = RandomForestClassifier(random_state=54)\n",
        "mlp = MLPClassifier(random_state=54)\n",
        "knn = KNeighborsClassifier()\n",
        "svm = SVC(random_state=54)\n",
        "\n",
        "models= [\n",
        "  forest, \n",
        "  mlp, \n",
        "  knn, \n",
        "  svm\n",
        "]\n",
        "\n",
        "cm_microstructure_models = {}\n",
        "\n",
        "print(\"{0:30} {1:30} {2}\".format('modelo', \n",
        "                                  'acuracia', \n",
        "                                  'f1 scores'))\n",
        "\n",
        "for model in models:\n",
        "  microstructure_pred = cross_val_predict(\n",
        "      model, \n",
        "      properties_droped_duplicates_normalized,\n",
        "      microstructure_droped_duplicates.values.reshape(-1,),\n",
        "      cv=k_folds \n",
        "    )\n",
        "\n",
        "  microstructure_multilabel_confusion_matrix = \\\n",
        "    multilabel_confusion_matrix(\n",
        "        microstructure_droped_duplicates,\n",
        "        microstructure_pred\n",
        "    )\n",
        "  \n",
        "  microstructure_confusion_matrix = \\\n",
        "    confusion_matrix(\n",
        "        microstructure_droped_duplicates,\n",
        "        microstructure_pred\n",
        "    )\n",
        "\n",
        "  clf_report = classification_report(\n",
        "      microstructure_droped_duplicates,\n",
        "      microstructure_pred,\n",
        "      output_dict=True\n",
        "    )\n",
        "  # print(clf_report.keys())\n",
        "  \n",
        "  f1_scores = []\n",
        "  for i in clf_report:\n",
        "    if is_float(i):\n",
        "      f1_scores.append(clf_report[i]['f1-score'])\n",
        "\n",
        "  # transform column index number to microstructure\n",
        "  clf_report = {categorical_key(k):v for (k,v) in clf_report.items()}\n",
        "\n",
        "  df_classification_report = pd.DataFrame(\n",
        "      clf_report\n",
        "    ).transpose()\n",
        "\n",
        "  model_name = str(model.__class__.__name__)\n",
        "\n",
        "  print('\\n Model: ', model_name)\n",
        "  print(df_classification_report)\n",
        "\n",
        "  # print(\"{0:30} {1:15} {2:30}\".format(model_name, \n",
        "  #                                 clf_report['accuracy'], \n",
        "  #                                 mean(f1_scores)))\n",
        "\n",
        "  cm_microstructure_models[model_name] = \\\n",
        "    microstructure_confusion_matrix\n",
        "\n",
        "  # make_confusion_matrix(microstructure_confusion_matrix, \n",
        "  #                       figsize=(10,8), \n",
        "  #                       categories=microstructures,cmap='Reds',\n",
        "  #                       title=model_name,\n",
        "  #                       count=False,\n",
        "  #                       file_name=model_name)\n",
        "\n",
        "\n",
        "  cm_analysis(microstructure_droped_duplicates,\n",
        "        microstructure_pred, model_name, [0.0,1.0,2.0,3.0,4.0,5.0,6.0], microstructures, \n",
        "        figsize=(10,8),\n",
        "         cmap=\"Reds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtWh3rs9-f0O"
      },
      "source": [
        "### 7.1 Avaliação utilizando conjunto de teste\n",
        "\n",
        "Verificar os modelos usando dados de teste "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVUw0GMf-tx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe8bfe1-b7de-4366-d8ec-a88c46125218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modelo                         acuracia                       f1 scores\n",
            "\n",
            " Model:  RandomForestClassifier\n",
            "\n",
            "\n",
            "RandomForestClassifier         0.7913043478260869             0.7674885916467238\n",
            "\n",
            " Model:  MLPClassifier\n",
            "\n",
            "\n",
            "MLPClassifier                  0.5565217391304348             0.4182164413764856\n",
            "\n",
            " Model:  KNeighborsClassifier\n",
            "\n",
            "\n",
            "KNeighborsClassifier           0.6260869565217392             0.5996861962310688\n",
            "\n",
            " Model:  SVC\n",
            "\n",
            "\n",
            "SVC                            0.591304347826087            0.46849052051162543\n"
          ]
        }
      ],
      "source": [
        "cm_microstructure_models_hml = {}\n",
        "\n",
        "print(\"{0:30} {1:30} {2}\".format('modelo', \n",
        "                                  'acuracia', \n",
        "                                  'f1 scores'))\n",
        "\n",
        "for model in models:\n",
        "\n",
        "  homolog_fit = model.fit(\n",
        "      x_train_normalized,\n",
        "      y_train_normalized.values.reshape(-1,)\n",
        "      )\n",
        "\n",
        "  caracteristic_homolog_pred = homolog_fit.predict(x_test_normalized)\n",
        "\n",
        "  clf_report_oversampled_homolog = classification_report(\n",
        "      y_test_normalized, \n",
        "      caracteristic_homolog_pred,\n",
        "      output_dict=True\n",
        "    )\n",
        "\n",
        "  microstructure_multilabel_confusion_matrix = \\\n",
        "    multilabel_confusion_matrix(\n",
        "      y_test_normalized, \n",
        "      caracteristic_homolog_pred,\n",
        "    )\n",
        "  \n",
        "  microstructure_confusion_matrix = \\\n",
        "    confusion_matrix(\n",
        "      y_test_normalized, \n",
        "      caracteristic_homolog_pred,\n",
        "    )\n",
        "\n",
        "  clf_report = classification_report(\n",
        "      y_test_normalized, \n",
        "      caracteristic_homolog_pred,\n",
        "      output_dict=True\n",
        "    )\n",
        "\n",
        "  f1_scores = []\n",
        "  for i in clf_report:\n",
        "    if is_float(i):\n",
        "      f1_scores.append(clf_report[i]['f1-score'])\n",
        "\n",
        "  # transform column index number to microstructure\n",
        "  clf_report = {categorical_key(k):v for (k,v) in clf_report.items()}\n",
        "\n",
        "  df_classification_report = pd.DataFrame(\n",
        "      clf_report\n",
        "    ).transpose()\n",
        "\n",
        "  model_name = str(model.__class__.__name__)\n",
        "\n",
        "  print('\\n Model: ', model_name)\n",
        "  # print(df_classification_report)\n",
        "\n",
        "  print('\\n')\n",
        "  print(\"{0:30} {1:15} {2:30}\".format(model_name, \n",
        "                                  clf_report['accuracy'], \n",
        "                                  mean(f1_scores)))\n",
        "\n",
        "  cm_microstructure_models[model_name] = \\\n",
        "    microstructure_confusion_matrix\n",
        "\n",
        "  make_confusion_matrix(microstructure_confusion_matrix, \n",
        "                        figsize=(10,8), \n",
        "                        categories=microstructures,cmap='Reds',\n",
        "                        title=model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T00NWe8gBCOA"
      },
      "source": [
        "### 7.2 Conclusão avaliação dos modelos\n",
        "\n",
        "Após avaliar o desempenho de diferentes modelos para o conjunto de dados sem duplicados, verificou-se a melhor performance do modelo radom forest, baseado na analise conjunta da acuracia, com f1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x98ia_vAulU"
      },
      "source": [
        "## 8. Criando sobreamostragem \n",
        "\n",
        "\n",
        "\n",
        "> Essa etapa se baseia na utilização de modelos para gerar novos dados para treinamento do modelo, de forma que possibilite uma dispersão dos dados, tornando o modelo mais genérico e reduzindo o overffiting do ajuste da curva.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs_hf0wg8rO-"
      },
      "outputs": [],
      "source": [
        "samplers = [\n",
        "    SMOTE(random_state=54),\n",
        "    ADASYN(random_state=54),\n",
        "    BorderlineSMOTE(random_state=54),\n",
        "    KMeansSMOTE(random_state=54),\n",
        "    SVMSMOTE(random_state=54),\n",
        "]\n",
        "\n",
        "\n",
        "data_oversampled = {}\n",
        "\n",
        "for sampler in samplers:\n",
        "\n",
        "  properties_train_oversampled, microstructure_train_oversampled = \\\n",
        "    sampler.fit_resample(x_train_normalized, \n",
        "    y_train_normalized.values.reshape(-1,)\n",
        "    )\n",
        "\n",
        "  properties_train_oversampled = pd.DataFrame(\n",
        "      properties_train_oversampled, \n",
        "      columns=x_train_normalized.columns\n",
        "    )\n",
        "\n",
        "  microstructure_train_oversampled = pd.DataFrame(\n",
        "      microstructure_train_oversampled, \n",
        "      columns=['PROPERTY: Microstructure']\n",
        "    )\n",
        "\n",
        "  data_oversampled[str(sampler.__class__.__name__)] = {\n",
        "      'properties_train_oversampled': properties_train_oversampled,\n",
        "      'microstructure_train_oversampled': microstructure_train_oversampled \n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viEX0fN0O10G",
        "outputId": "25b40df8-c844-485c-a48b-50dd27646885"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(473, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "microstructure_train_oversampled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idQ8B2IwClQP"
      },
      "source": [
        "### 8.1 Verificando o desempenho dos diferentes tipos de sobre amostragem \n",
        "> Através do cross validation, será verificado o comportamento dos diferentes tipos de modelos de sobre amostragem, utilizando apenas o classificador random forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZED4Mn-g-oF2",
        "outputId": "f8dbca23-ab42-463d-8109-95dfcbb8eaea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "media f1 scores:  0.8219680679567752\n",
            "Sampler:  SMOTE\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.802632  0.824324  0.813333   74.000000\n",
            "BCC ++         0.838235  0.770270  0.802817   74.000000\n",
            "BCC B2         0.870130  0.905405  0.887417   74.000000\n",
            "FCC            0.743243  0.743243  0.743243   74.000000\n",
            "FCC ++         0.777778  0.756757  0.767123   74.000000\n",
            "FCC BCC        0.818182  0.851351  0.834437   74.000000\n",
            "OTHER          0.905405  0.905405  0.905405   74.000000\n",
            "accuracy       0.822394  0.822394  0.822394    0.822394\n",
            "macro avg      0.822229  0.822394  0.821968  518.000000\n",
            "weighted avg   0.822229  0.822394  0.821968  518.000000\n",
            "\n",
            "\n",
            "media f1 scores:  0.8096088006604392\n",
            "Sampler:  ADASYN\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.789474  0.810811  0.800000   74.000000\n",
            "BCC ++         0.813333  0.743902  0.777070   82.000000\n",
            "BCC B2         0.825581  0.910256  0.865854   78.000000\n",
            "FCC            0.706667  0.736111  0.721088   72.000000\n",
            "FCC ++         0.770270  0.750000  0.760000   76.000000\n",
            "FCC BCC        0.875000  0.843373  0.858896   83.000000\n",
            "OTHER          0.890411  0.878378  0.884354   74.000000\n",
            "accuracy       0.810761  0.810761  0.810761    0.810761\n",
            "macro avg      0.810105  0.810405  0.809609  539.000000\n",
            "weighted avg   0.811588  0.810761  0.810511  539.000000\n",
            "\n",
            "\n",
            "media f1 scores:  0.8340188557753819\n",
            "Sampler:  BorderlineSMOTE\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.821918  0.810811  0.816327   74.000000\n",
            "BCC ++         0.833333  0.810811  0.821918   74.000000\n",
            "BCC B2         0.884615  0.932432  0.907895   74.000000\n",
            "FCC            0.753247  0.783784  0.768212   74.000000\n",
            "FCC ++         0.797297  0.797297  0.797297   74.000000\n",
            "FCC BCC        0.835616  0.824324  0.829932   74.000000\n",
            "OTHER          0.915493  0.878378  0.896552   74.000000\n",
            "accuracy       0.833977  0.833977  0.833977    0.833977\n",
            "macro avg      0.834503  0.833977  0.834019  518.000000\n",
            "weighted avg   0.834503  0.833977  0.834019  518.000000\n",
            "\n",
            "\n",
            "media f1 scores:  0.8181424825712027\n",
            "Sampler:  KMeansSMOTE\n",
            "              precision    recall  f1-score    support\n",
            "BCC            0.740741  0.810811  0.774194   74.00000\n",
            "BCC ++         0.805556  0.763158  0.783784   76.00000\n",
            "BCC B2         0.880000  0.891892  0.885906   74.00000\n",
            "FCC            0.759036  0.828947  0.792453   76.00000\n",
            "FCC ++         0.833333  0.779221  0.805369   77.00000\n",
            "FCC BCC        0.833333  0.800000  0.816327   75.00000\n",
            "OTHER          0.887324  0.851351  0.868966   74.00000\n",
            "accuracy       0.817490  0.817490  0.817490    0.81749\n",
            "macro avg      0.819903  0.817911  0.818142  526.00000\n",
            "weighted avg   0.819719  0.817490  0.817838  526.00000\n",
            "\n",
            "\n",
            "media f1 scores:  0.8090819517575327\n",
            "Sampler:  SVMSMOTE\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.789474  0.810811  0.800000   74.000000\n",
            "BCC ++         0.826087  0.770270  0.797203   74.000000\n",
            "BCC B2         0.864865  0.864865  0.864865   74.000000\n",
            "FCC            0.779221  0.810811  0.794702   74.000000\n",
            "FCC ++         0.824324  0.824324  0.824324   74.000000\n",
            "FCC BCC        0.840000  0.851351  0.845638   74.000000\n",
            "OTHER          0.750000  0.724138  0.736842   29.000000\n",
            "accuracy       0.816068  0.816068  0.816068    0.816068\n",
            "macro avg      0.810567  0.808081  0.809082  473.000000\n",
            "weighted avg   0.816329  0.816068  0.815955  473.000000\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# properties_oversampled, microstructure_oversampled\n",
        "from statistics import mean\n",
        "cm_microstructure_oversampled = {}\n",
        "\n",
        "\n",
        "\n",
        "for oversampled in data_oversampled.keys():\n",
        "  microstructure_pred_oversampled = cross_val_predict(\n",
        "      default_forest, \n",
        "      data_oversampled[oversampled]['properties_train_oversampled'], \n",
        "      data_oversampled[oversampled]['microstructure_train_oversampled'],\n",
        "      cv=k_folds\n",
        "    )\n",
        "\n",
        "  microstructure_multilabel_confusion_matrix_oversampled = \\\n",
        "    multilabel_confusion_matrix(\n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "        microstructure_pred_oversampled\n",
        "    )\n",
        "  \n",
        "  microstructure_confusion_matrix_oversampled = \\\n",
        "    confusion_matrix(\n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "        microstructure_pred_oversampled\n",
        "    )\n",
        "\n",
        "  clf_report_oversampled = classification_report(\n",
        "      data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "      microstructure_pred_oversampled,\n",
        "      output_dict=True\n",
        "    )\n",
        "  \n",
        "  f1_scores = []\n",
        "  for i in clf_report_oversampled:\n",
        "    if is_float(i):\n",
        "      f1_scores.append(clf_report_oversampled[i]['f1-score'])\n",
        "  print('media f1 scores: ',mean(f1_scores))\n",
        "\n",
        "  # transform column index number to microstructure\n",
        "  clf_report_oversampled = {categorical_key(k):v for (k,v) in clf_report_oversampled.items()}\n",
        "\n",
        "  df_classification_report_oversampled = pd.DataFrame(\n",
        "      clf_report_oversampled\n",
        "    ).transpose()\n",
        "\n",
        "  print('Sampler: ',oversampled)\n",
        "  print(df_classification_report_oversampled)\n",
        "\n",
        "  cm_microstructure_oversampled[oversampled] = \\\n",
        "    microstructure_confusion_matrix_oversampled\n",
        "\n",
        "  # make_confusion_matrix(microstructure_confusion_matrix_oversampled, \n",
        "  #                       figsize=(7,7), \n",
        "  #                       categories=microstructures,cmap='Reds',\n",
        "  #                       title=oversampled)\n",
        "\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtM8ExHJiiGs",
        "outputId": "e31f5226-8ce8-4da3-cf58-fdd2e093e42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "media f1 scores:  0.7207527319871038\n",
            "Sampler:  SMOTE\n",
            "              precision    recall  f1-score    support\n",
            "BCC            0.857143  0.909091  0.882353   33.00000\n",
            "BCC ++         0.833333  0.625000  0.714286   16.00000\n",
            "BCC B2         0.888889  0.888889  0.888889    9.00000\n",
            "FCC            0.565217  0.722222  0.634146   18.00000\n",
            "FCC ++         0.800000  0.444444  0.571429   18.00000\n",
            "FCC BCC        0.578947  0.846154  0.687500   13.00000\n",
            "OTHER          0.714286  0.625000  0.666667    8.00000\n",
            "accuracy       0.739130  0.739130  0.739130    0.73913\n",
            "macro avg      0.748259  0.722971  0.720753  115.00000\n",
            "weighted avg   0.760292  0.739130  0.734934  115.00000\n",
            "\n",
            "\n",
            "media f1 scores:  0.7466030090196998\n",
            "Sampler:  ADASYN\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.810811  0.909091  0.857143   33.000000\n",
            "BCC ++         0.846154  0.687500  0.758621   16.000000\n",
            "BCC B2         0.888889  0.888889  0.888889    9.000000\n",
            "FCC            0.625000  0.555556  0.588235   18.000000\n",
            "FCC ++         0.916667  0.611111  0.733333   18.000000\n",
            "FCC BCC        0.545455  0.923077  0.685714   13.000000\n",
            "OTHER          0.833333  0.625000  0.714286    8.000000\n",
            "accuracy       0.756522  0.756522  0.756522    0.756522\n",
            "macro avg      0.780901  0.742889  0.746603  115.000000\n",
            "weighted avg   0.780894  0.756522  0.755134  115.000000\n",
            "\n",
            "\n",
            "media f1 scores:  0.7166255087642998\n",
            "Sampler:  BorderlineSMOTE\n",
            "              precision    recall  f1-score    support\n",
            "BCC            0.810811  0.909091  0.857143   33.00000\n",
            "BCC ++         0.785714  0.687500  0.733333   16.00000\n",
            "BCC B2         0.875000  0.777778  0.823529    9.00000\n",
            "FCC            0.588235  0.555556  0.571429   18.00000\n",
            "FCC ++         0.846154  0.611111  0.709677   18.00000\n",
            "FCC BCC        0.571429  0.923077  0.705882   13.00000\n",
            "OTHER          0.800000  0.500000  0.615385    8.00000\n",
            "accuracy       0.739130  0.739130  0.739130    0.73913\n",
            "macro avg      0.753906  0.709159  0.716626  115.00000\n",
            "weighted avg   0.755224  0.739130  0.735568  115.00000\n",
            "\n",
            "\n",
            "media f1 scores:  0.6942530788649746\n",
            "Sampler:  KMeansSMOTE\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.805556  0.878788  0.840580   33.000000\n",
            "BCC ++         0.785714  0.687500  0.733333   16.000000\n",
            "BCC B2         0.875000  0.777778  0.823529    9.000000\n",
            "FCC            0.526316  0.555556  0.540541   18.000000\n",
            "FCC ++         0.818182  0.500000  0.620690   18.000000\n",
            "FCC BCC        0.545455  0.923077  0.685714   13.000000\n",
            "OTHER          0.800000  0.500000  0.615385    8.000000\n",
            "accuracy       0.713043  0.713043  0.713043    0.713043\n",
            "macro avg      0.736603  0.688957  0.694253  115.000000\n",
            "weighted avg   0.736710  0.713043  0.709772  115.000000\n",
            "\n",
            "\n",
            "media f1 scores:  0.7614048307495042\n",
            "Sampler:  SVMSMOTE\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.769231  0.909091  0.833333   33.000000\n",
            "BCC ++         0.833333  0.625000  0.714286   16.000000\n",
            "BCC B2         0.875000  0.777778  0.823529    9.000000\n",
            "FCC            0.722222  0.722222  0.722222   18.000000\n",
            "FCC ++         0.846154  0.611111  0.709677   18.000000\n",
            "FCC BCC        0.684211  1.000000  0.812500   13.000000\n",
            "OTHER          0.833333  0.625000  0.714286    8.000000\n",
            "accuracy       0.773913  0.773913  0.773913    0.773913\n",
            "macro avg      0.794783  0.752886  0.761405  115.000000\n",
            "weighted avg   0.785958  0.773913  0.768620  115.000000\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "default_forest = RandomForestClassifier()\n",
        "\n",
        "cm_microstructure_oversampled_homolog = {}\n",
        "\n",
        "for oversampled in data_oversampled.keys():\n",
        "  \n",
        "\n",
        "  homolog_fit = default_forest.fit(\n",
        "      data_oversampled[oversampled]['properties_train_oversampled'], \n",
        "      data_oversampled[oversampled]['microstructure_train_oversampled']\n",
        "      )\n",
        "\n",
        "# y_train_normalized\n",
        "  caracteristic_homolog_pred = homolog_fit.predict(x_test_normalized)\n",
        "\n",
        "  clf_report_oversampled_homolog = classification_report(\n",
        "      y_test_normalized, \n",
        "      caracteristic_homolog_pred,\n",
        "      output_dict=True\n",
        "    )\n",
        "\n",
        "  f1_scores = []\n",
        "  for i in clf_report_oversampled_homolog:\n",
        "    if is_float(i):\n",
        "      f1_scores.append(clf_report_oversampled_homolog[i]['f1-score'])\n",
        "  print('media f1 scores: ',mean(f1_scores))\n",
        "\n",
        "  # transform column index number to microstructure\n",
        "  clf_report_oversampled_homolog = {categorical_key(k):v for (k,v) in clf_report_oversampled_homolog.items()}\n",
        "\n",
        "  df_classification_report_oversampled_homolog = pd.DataFrame(\n",
        "      clf_report_oversampled_homolog\n",
        "    ).transpose()\n",
        "\n",
        "  print('Sampler: ',oversampled)\n",
        "  print(df_classification_report_oversampled_homolog)\n",
        "\n",
        "  cm_microstructure_oversampled_homolog[oversampled] = confusion_matrix(\n",
        "      y_test_droped_duplicates, \n",
        "      caracteristic_homolog_pred,\n",
        "  )\n",
        "\n",
        "  # make_confusion_matrix(cm_microstructure_oversampled_homolog[oversampled], \n",
        "  #                       figsize=(7,7), \n",
        "  #                       categories=microstructures,cmap='Reds',\n",
        "  #                       title=oversampled)\n",
        "\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h4Jb3UorBSK"
      },
      "source": [
        "## 8.2 Validando modelos e sobreamostragens pela acurácia e média de F1 scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2.1 Avaliando modelos nos diferentes tipos de sobreamostragem com corss-validation"
      ],
      "metadata": {
        "id": "pyBI_tkBd-Hj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74q3X_M8rAbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47abf8ee-a0a6-4445-983f-6b9cdb0d775b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dados  sobreamostrados Cross validation\n",
            "\n",
            "\n",
            "RandomForestClassifier         acuracia                       f1 scores\n",
            "SMOTE                          0.8243243243243243             0.8241776338468789\n",
            "ADASYN                         0.8089053803339518             0.8073868799538095\n",
            "BorderlineSMOTE                0.8359073359073359             0.8360356677051026\n",
            "KMeansSMOTE                    0.8307984790874525             0.8314721859566849\n",
            "SVMSMOTE                       0.828752642706131             0.8166939069512529\n"
          ]
        }
      ],
      "source": [
        "# properties_oversampled, microstructure_oversampled\n",
        "print('dados  sobreamostrados Cross validation')\n",
        "\n",
        "cm_microstructure_oversampled = {}\n",
        "\n",
        "models = [models[0]]\n",
        "\n",
        "for model in models:\n",
        "\n",
        "  model_name = str(model.__class__.__name__)\n",
        "  print('\\n')\n",
        "  print(\"{0:30} {1:30} {2}\".format(model_name, \n",
        "                                  'acuracia', \n",
        "                                  'f1 scores'))\n",
        "\n",
        "  for oversampled in data_oversampled.keys():\n",
        "  \n",
        "    \n",
        "    microstructure_pred_oversampled = cross_val_predict(\n",
        "        model, \n",
        "        data_oversampled[oversampled]['properties_train_oversampled'], \n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled'],\n",
        "        cv=15\n",
        "      )\n",
        "\n",
        "    microstructure_multilabel_confusion_matrix_oversampled = \\\n",
        "      multilabel_confusion_matrix(\n",
        "          data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "          microstructure_pred_oversampled\n",
        "      )\n",
        "    \n",
        "    microstructure_confusion_matrix_oversampled = \\\n",
        "      confusion_matrix(\n",
        "          data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "          microstructure_pred_oversampled\n",
        "      )\n",
        "\n",
        "    clf_report_oversampled = classification_report(\n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "        microstructure_pred_oversampled,\n",
        "        output_dict=True\n",
        "      )\n",
        "    \n",
        "    f1_scores = []\n",
        "    for i in clf_report_oversampled:\n",
        "      if is_float(i):\n",
        "        f1_scores.append(clf_report_oversampled[i]['f1-score'])\n",
        "\n",
        "    # transform column index number to microstructure\n",
        "    clf_report_oversampled = {categorical_key(k):v for (k,v) in clf_report_oversampled.items()}\n",
        "\n",
        "    df_classification_report_oversampled = pd.DataFrame(\n",
        "        clf_report_oversampled\n",
        "      ).transpose()\n",
        "\n",
        "    print(\"{0:30} {1:15} {2:30}\".format(oversampled, \n",
        "                                  clf_report_oversampled['accuracy'], \n",
        "                                  mean(f1_scores)))\n",
        "\n",
        "    cm_microstructure_oversampled[oversampled] = \\\n",
        "      microstructure_confusion_matrix_oversampled\n",
        "\n",
        "    # make_confusion_matrix(microstructure_confusion_matrix_oversampled, \n",
        "    #                       figsize=(7,7), \n",
        "    #                       categories=microstructures,cmap='Reds',\n",
        "    #                       title=f'{oversampled} - {model_name}')\n",
        "\n",
        "    cm_analysis(data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "          microstructure_pred_oversampled, oversampled, [0.0,1.0,2.0,3.0,4.0,5.0,6.0], microstructures, \n",
        "      figsize=(8,8),\n",
        "        cmap=\"Reds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2.2 Validando diferentes modelos com diferentes sobreamostragem com os dados de teste"
      ],
      "metadata": {
        "id": "dzrSfuWdeKPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6u1BNbFrxld",
        "outputId": "d7b5c1e5-75c7-4358-8efa-cd08d1f4ac7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validacao dados sobreamostrados\n",
            "\n",
            "\n",
            "RandomForestClassifier         acuracia                       f1 scores\n",
            "SMOTE                          0.7739130434782608             0.7605891005050669\n",
            "ADASYN                         0.7478260869565218             0.7273428970907962\n",
            "BorderlineSMOTE                0.808695652173913             0.7968267667004204\n",
            "KMeansSMOTE                    0.7304347826086957             0.6923705264041399\n",
            "SVMSMOTE                       0.782608695652174             0.7639959480930443\n"
          ]
        }
      ],
      "source": [
        "# default_forest = RandomForestClassifier()\n",
        "print('validacao dados sobreamostrados')\n",
        "\n",
        "cm_microstructure_oversampled_homolog = {}\n",
        "\n",
        "for model in models:\n",
        "\n",
        "  model_name = str(model.__class__.__name__)\n",
        "  print('\\n')\n",
        "  print(\"{0:30} {1:30} {2}\".format(model_name, \n",
        "                                  'acuracia', \n",
        "                                  'f1 scores'))\n",
        "\n",
        "  for oversampled in data_oversampled.keys():\n",
        "\n",
        "    homolog_fit = model.fit(\n",
        "        data_oversampled[oversampled]['properties_train_oversampled'], \n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled']\n",
        "        )\n",
        "\n",
        "    caracteristic_homolog_pred = homolog_fit.predict(x_test_normalized)\n",
        "\n",
        "    clf_report_oversampled_homolog = classification_report(\n",
        "        y_test_normalized, \n",
        "        caracteristic_homolog_pred,\n",
        "        output_dict=True\n",
        "      )\n",
        "\n",
        "    f1_scores = []\n",
        "    for i in clf_report_oversampled_homolog:\n",
        "      if is_float(i):\n",
        "        f1_scores.append(clf_report_oversampled_homolog[i]['f1-score'])\n",
        "\n",
        "    # transform column index number to microstructure\n",
        "    clf_report_oversampled_homolog = {categorical_key(k):v for (k,v) in clf_report_oversampled_homolog.items()}\n",
        "\n",
        "    df_classification_report_oversampled_homolog = pd.DataFrame(\n",
        "        clf_report_oversampled_homolog\n",
        "      ).transpose()\n",
        "\n",
        "\n",
        "    print(\"{0:30} {1:15} {2:30}\".format(oversampled, \n",
        "                                  clf_report_oversampled_homolog['accuracy'], \n",
        "                                  mean(f1_scores)))\n",
        "\n",
        "    cm_microstructure_oversampled_homolog[oversampled] = confusion_matrix(\n",
        "        y_test_droped_duplicates, \n",
        "        caracteristic_homolog_pred,\n",
        "    )\n",
        "\n",
        "    # make_confusion_matrix(cm_microstructure_oversampled_homolog[oversampled], \n",
        "    #                       figsize=(7,7), \n",
        "    #                       categories=microstructures,cmap='Reds',\n",
        "    #                       title=f'{oversampled} - {model_name}')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvsxKTduz0zR"
      },
      "source": [
        "### 8.2.3 Conclusão comparação de modelos e sobreamostragens\n",
        "\n",
        "Após a avaliação dos modelos em conjunto com o tipo de sobreamostragem, ficou claro que o modelo Random Forest em conjunto com a sobreamostragem BorderlineSMOTE  apresentaram os melhores resultados.\n",
        "\n",
        "Sendo assim, a próxima etapa será analizar a melhor combinação de hiperparâmetros."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_oversampled = 'BorderlineSMOTE'"
      ],
      "metadata": {
        "id": "Crsl1p77iOZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzuFiYZI5KVK"
      },
      "source": [
        "## 9 Avaliando hiperparâmetros dos modelos\n",
        "\n",
        "Nesta etapa, serão avaliados os melhores hiperparâmetros para o modelo RandoForest, considerando os dados sobre amostrados, e os dados originais sem duplicados e normalizados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3DCdnO1EVk0"
      },
      "source": [
        "### 9.2 Otimizando hiperparâmetros dos dados sobreamostrados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAYdeq1jo5an",
        "outputId": "9d74b0bf-75b4-436b-c582-3ce8d91024dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 70 candidates, totalling 700 fits\n",
            "{'criterion': 'entropy', 'max_depth': 15, 'max_features': 'auto', 'n_estimators': 22}\n"
          ]
        }
      ],
      "source": [
        "parameters = {\n",
        "    'criterion': ['entropy', 'gini'],\n",
        "    'n_estimators': [21,22,23,24,190,195,200],\n",
        "    'max_depth': [11,12,13,14,15],\n",
        "    'max_features': ['auto']\n",
        "} \n",
        "\n",
        "# oversamplers = ['SMOTE', 'ADASYN', 'BorderlineSMOTE', 'KMeansSMOTE', 'SVMSMOTE']\n",
        "\n",
        "oversampled = 'BorderlineSMOTE'\n",
        "\n",
        "regressor = GridSearchCV(RandomForestClassifier(random_state=54), parameters, verbose=1,cv=10,n_jobs=-1) \n",
        "\n",
        "# for oversampled in oversamplers:\n",
        "\n",
        "regressor.fit(data_oversampled[best_oversampled]['properties_train_oversampled'].to_numpy(), \n",
        "      data_oversampled[best_oversampled]['microstructure_train_oversampled'].to_numpy()) \n",
        "\n",
        "  # print(oversampled)\n",
        "print(regressor.best_params_)\n",
        "# regressor.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V47RyJnppcWt"
      },
      "source": [
        "Histórico de busca por melhores parametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4oDpHGK5u9C"
      },
      "outputs": [],
      "source": [
        "# Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
        "# GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=54),\n",
        "#              n_jobs=-1,\n",
        "#              param_grid={'criterion': ['entropy', 'gini'],\n",
        "#                          'max_depth': [11, 12, 13, 14, 15],\n",
        "#                          'max_features': ['auto'],\n",
        "#                          'n_estimators': [21, 22, 23, 24]},\n",
        "#              verbose=1)\n",
        "\n",
        "# Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
        "# GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=54),\n",
        "#              n_jobs=-1,\n",
        "#              param_grid={'criterion': ['entropy', 'gini'],\n",
        "#                          'max_depth': [11, 12, 13, 15],\n",
        "#                          'max_features': ['auto'],\n",
        "#                          'n_estimators': [20, 23, 24]},\n",
        "#              verbose=1)\n",
        "\n",
        "# Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
        "# GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=54),\n",
        "#              n_jobs=-1,\n",
        "#              param_grid={'criterion': ['entropy', 'gini'],\n",
        "#                          'max_depth': [12, 15, 17], 'max_features': ['auto'],\n",
        "#                          'n_estimators': [12, 15, 20, 23]},\n",
        "#              verbose=1)\n",
        "\n",
        "# Fitting 10 folds for each of 70 candidates, totalling 700 fits\n",
        "# GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=54),\n",
        "#              n_jobs=-1,\n",
        "#              param_grid={'criterion': ['entropy', 'gini'],\n",
        "#                          'max_depth': [6, 10, 12, 15, 18],\n",
        "#                          'max_features': ['auto'],\n",
        "#                          'n_estimators': [1, 10, 20, 25, 30, 50, 60]},\n",
        "#              verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ6Ae8JXpxxc"
      },
      "source": [
        "Uma vez que os hiperparâmetros foram otimizados, é realizada a etapa para verificar o comportamento do modelo em conjuntos de dados simulados com composições variaveis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2.1 Avaliando hiperparâmetros através do cross validation "
      ],
      "metadata": {
        "id": "WV2WTHGPhkOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_hyperparams_adjusted =  RandomForestClassifier(\n",
        "    max_depth=15,\n",
        "    random_state=54, \n",
        "    criterion='entropy', \n",
        "    max_features='auto',\n",
        "    n_estimators = 22,\n",
        "    )\n",
        "\n",
        "\n",
        "# properties_oversampled, microstructure_oversampled\n",
        "print('dados  sobreamostrados Cross validation (hiperparametros)')\n",
        "\n",
        "cm_microstructure_oversampled = {}\n",
        "\n",
        "models = [models[0]]\n",
        "\n",
        "for model in [model_hyperparams_adjusted]:\n",
        "\n",
        "  model_name = str(model.__class__.__name__)\n",
        "  print('\\n')\n",
        "  print(\"{0:30} {1:30} {2}\".format(model_name, \n",
        "                                  'acuracia', \n",
        "                                  'f1 scores'))\n",
        "\n",
        "  for oversampled in [best_oversampled]:\n",
        "  \n",
        "    \n",
        "    microstructure_pred_oversampled = cross_val_predict(\n",
        "        model, \n",
        "        data_oversampled[oversampled]['properties_train_oversampled'], \n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled'],\n",
        "        cv=15\n",
        "      )\n",
        "\n",
        "    microstructure_multilabel_confusion_matrix_oversampled = \\\n",
        "      multilabel_confusion_matrix(\n",
        "          data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "          microstructure_pred_oversampled\n",
        "      )\n",
        "    \n",
        "    microstructure_confusion_matrix_oversampled = \\\n",
        "      confusion_matrix(\n",
        "          data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "          microstructure_pred_oversampled\n",
        "      )\n",
        "\n",
        "    clf_report_oversampled = classification_report(\n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "        microstructure_pred_oversampled,\n",
        "        output_dict=True\n",
        "      )\n",
        "    \n",
        "    f1_scores = []\n",
        "    for i in clf_report_oversampled:\n",
        "      if is_float(i):\n",
        "        f1_scores.append(clf_report_oversampled[i]['f1-score'])\n",
        "\n",
        "    # transform column index number to microstructure\n",
        "    clf_report_oversampled = {categorical_key(k):v for (k,v) in clf_report_oversampled.items()}\n",
        "\n",
        "    df_classification_report_oversampled = pd.DataFrame(\n",
        "        clf_report_oversampled\n",
        "      ).transpose()\n",
        "\n",
        "    print(\"{0:30} {1:15} {2:30}\".format(oversampled, \n",
        "                                  clf_report_oversampled['accuracy'], \n",
        "                                  mean(f1_scores)))\n",
        "\n",
        "    cm_microstructure_oversampled[oversampled] = \\\n",
        "      microstructure_confusion_matrix_oversampled\n",
        "\n",
        "    # make_confusion_matrix(microstructure_confusion_matrix_oversampled, \n",
        "    #                       figsize=(7,7), \n",
        "    #                       categories=microstructures,cmap='Reds',\n",
        "    #                       title=f'{oversampled} - {model_name}')\n",
        "\n",
        "    cm_analysis(data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "          microstructure_pred_oversampled, oversampled, [0.0,1.0,2.0,3.0,4.0,5.0,6.0], microstructures, \n",
        "      figsize=(8,8),\n",
        "        cmap=\"Reds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N1tgqieha5b",
        "outputId": "0f16e746-0108-479a-d4cd-1e0944da3404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dados  sobreamostrados Cross validation (hiperparametros)\n",
            "\n",
            "\n",
            "RandomForestClassifier         acuracia                       f1 scores\n",
            "BorderlineSMOTE                0.8262548262548263             0.8264305640609987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2.2 Validando hiperparâmetros do modelo com dados sobreamostrados usando dados de teste"
      ],
      "metadata": {
        "id": "4c70JMr6inOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3_oTjgzxi3Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# properties_oversampled, microstructure_oversampled\n",
        "print('dados  sobreamostrados Cross validation')\n",
        "\n",
        "cm_microstructure_oversampled = {}\n",
        "\n",
        "models = [models[0]]\n",
        "\n",
        "for model in models:\n",
        "\n",
        "  model_name = str(model.__class__.__name__)\n",
        "  print('\\n')\n",
        "  print(\"{0:30} {1:30} {2}\".format(model_name, \n",
        "                                  'acuracia', \n",
        "                                  'f1 scores'))\n",
        "\n",
        "  for oversampled in data_oversampled.keys():\n",
        "  \n",
        "    \n",
        "    microstructure_pred_oversampled = cross_val_predict(\n",
        "        model, \n",
        "        data_oversampled[oversampled]['properties_train_oversampled'], \n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled'],\n",
        "        cv=15\n",
        "      )\n",
        "\n",
        "    microstructure_multilabel_confusion_matrix_oversampled = \\\n",
        "      multilabel_confusion_matrix(\n",
        "          data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "          microstructure_pred_oversampled\n",
        "      )\n",
        "    \n",
        "    microstructure_confusion_matrix_oversampled = \\\n",
        "      confusion_matrix(\n",
        "          data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "          microstructure_pred_oversampled\n",
        "      )\n",
        "\n",
        "    clf_report_oversampled = classification_report(\n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "        microstructure_pred_oversampled,\n",
        "        output_dict=True\n",
        "      )\n",
        "    \n",
        "    f1_scores = []\n",
        "    for i in clf_report_oversampled:\n",
        "      if is_float(i):\n",
        "        f1_scores.append(clf_report_oversampled[i]['f1-score'])\n",
        "\n",
        "    # transform column index number to microstructure\n",
        "    clf_report_oversampled = {categorical_key(k):v for (k,v) in clf_report_oversampled.items()}\n",
        "\n",
        "    df_classification_report_oversampled = pd.DataFrame(\n",
        "        clf_report_oversampled\n",
        "      ).transpose()\n",
        "\n",
        "    print(\"{0:30} {1:15} {2:30}\".format(oversampled, \n",
        "                                  clf_report_oversampled['accuracy'], \n",
        "                                  mean(f1_scores)))\n",
        "\n",
        "    cm_microstructure_oversampled[oversampled] = \\\n",
        "      microstructure_confusion_matrix_oversampled\n",
        "\n",
        "    # make_confusion_matrix(microstructure_confusion_matrix_oversampled, \n",
        "    #                       figsize=(7,7), \n",
        "    #                       categories=microstructures,cmap='Reds',\n",
        "    #                       title=f'{oversampled} - {model_name}')\n",
        "\n",
        "    cm_analysis(data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "          microstructure_pred_oversampled, oversampled, [0.0,1.0,2.0,3.0,4.0,5.0,6.0], microstructures, \n",
        "      figsize=(8,8),\n",
        "        cmap=\"Reds\")\n"
      ],
      "metadata": {
        "id": "B-JzJpUchW-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q77mV8FkBAg_"
      },
      "source": [
        "### 9.3 Avaliação dos hiperparâmetros nos dados sem sobreamostragem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4mLKC_fE-zG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535bf8a0-abcd-430c-9002-efdab3b38962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
            "{'criterion': 'gini', 'max_depth': 13, 'max_features': 'auto', 'n_estimators': 199}\n"
          ]
        }
      ],
      "source": [
        "parameters = {\n",
        "    'max_depth': [13,14,15],\n",
        "    'criterion': ['gini'],\n",
        "    'n_estimators': [199,200],\n",
        "    \n",
        "    'max_features': ['auto']\n",
        "}\n",
        "\n",
        "\n",
        "# oversamplers = ['SMOTE', 'ADASYN', 'BorderlineSMOTE', 'KMeansSMOTE', 'SVMSMOTE']\n",
        "\n",
        "oversampled = 'KMeansSMOTE'\n",
        "\n",
        "regressor = GridSearchCV(RandomForestClassifier(random_state=54), parameters, verbose=1,cv=10,n_jobs=-1) \n",
        "\n",
        "# for oversampled in oversamplers:\n",
        "\n",
        "regressor.fit(properties_droped_duplicates_normalized.to_numpy(), \n",
        "      microstructure_droped_duplicates) \n",
        "\n",
        "  # print(oversampled)\n",
        "print(regressor.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "microstructure_droped_duplicates.shape"
      ],
      "metadata": {
        "id": "DwNJRumaP2_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzcVJPKypxGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb1c8b6-5810-4298-e198-aeb9f55c5e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model:  RandomForestClassifier\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.714286  0.794393  0.752212  107.000000\n",
            "BCC ++         0.590909  0.393939  0.472727   66.000000\n",
            "BCC B2         0.617647  0.677419  0.646154   31.000000\n",
            "FCC            0.544304  0.693548  0.609929   62.000000\n",
            "FCC ++         0.688889  0.584906  0.632653   53.000000\n",
            "FCC BCC        0.488372  0.500000  0.494118   42.000000\n",
            "OTHER          0.444444  0.380952  0.410256   21.000000\n",
            "accuracy       0.615183  0.615183  0.615183    0.615183\n",
            "macro avg      0.584122  0.575023  0.574007  382.000000\n",
            "weighted avg   0.614342  0.615183  0.608461  382.000000\n"
          ]
        }
      ],
      "source": [
        "model_hyperparams_adjusted =  RandomForestClassifier(\n",
        "    max_depth=13,\n",
        "    random_state=54, \n",
        "    criterion='gini', \n",
        "    max_features='auto',\n",
        "    n_estimators = 195,\n",
        "    )\n",
        "\n",
        "\n",
        "# model_hyperparams_adjusted =  RandomForestClassifier(\n",
        "#     max_depth=100,\n",
        "#     criterion='entropy',\n",
        "#     random_state=54\n",
        "#     )\n",
        "\n",
        "microstructure_pred = cross_val_predict(\n",
        "    model_hyperparams_adjusted, \n",
        "    properties_droped_duplicates_normalized,\n",
        "    microstructure_droped_duplicates.values.reshape(-1,),\n",
        "    cv=k_folds \n",
        "  )\n",
        "\n",
        "microstructure_multilabel_confusion_matrix = \\\n",
        "  multilabel_confusion_matrix(\n",
        "      microstructure_droped_duplicates,\n",
        "      microstructure_pred\n",
        "  )\n",
        "\n",
        "microstructure_confusion_matrix = \\\n",
        "  confusion_matrix(\n",
        "      microstructure_droped_duplicates,\n",
        "      microstructure_pred\n",
        "  )\n",
        "\n",
        "clf_report = classification_report(\n",
        "    microstructure_droped_duplicates,\n",
        "    microstructure_pred,\n",
        "    output_dict=True\n",
        "  )\n",
        "\n",
        "# transform column index number to microstructure\n",
        "clf_report = {categorical_key(k):v for (k,v) in clf_report.items()}\n",
        "\n",
        "df_classification_report = pd.DataFrame(\n",
        "    clf_report\n",
        "  ).transpose()\n",
        "\n",
        "model_name = str(model_hyperparams_adjusted.__class__.__name__)\n",
        "\n",
        "print('\\n Model: ', model_name)\n",
        "print(df_classification_report)\n",
        "\n",
        "# cm_microstructure_models[model_name] = \\\n",
        "#   microstructure_confusion_matrix\n",
        "\n",
        "# make_confusion_matrix(microstructure_confusion_matrix, \n",
        "#                       figsize=(10,8), \n",
        "#                       categories=microstructures,cmap='Reds',\n",
        "#                       title=model_name)\n",
        "\n",
        "# cm_analysis(microstructure_droped_duplicates,\n",
        "#       microstructure_pred, model_name, [0.0,1.0,2.0,3.0,4.0,5.0,6.0], microstructures, \n",
        "#       figsize=(8,7),\n",
        "#         cmap=\"Reds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LGI8urQblbR"
      },
      "outputs": [],
      "source": [
        "#  Model:  RandomForestClassifier\n",
        "#               precision    recall  f1-score     support\n",
        "# BCC            0.691667  0.775701  0.731278  107.000000\n",
        "# BCC ++         0.555556  0.378788  0.450450   66.000000\n",
        "# BCC B2         0.473684  0.580645  0.521739   31.000000\n",
        "# FCC            0.493333  0.596774  0.540146   62.000000\n",
        "# FCC ++         0.595238  0.471698  0.526316   53.000000\n",
        "# FCC BCC        0.560976  0.547619  0.554217   42.000000\n",
        "# OTHER          0.380952  0.380952  0.380952   21.000000\n",
        "# accuracy       0.573298  0.573298  0.573298    0.573298\n",
        "# macro avg      0.535915  0.533168  0.529300  382.000000\n",
        "# weighted avg   0.573441  0.573298  0.567569  382.000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trn63m2Kq7G8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645aa01e-10bb-41e6-b3e1-10e6b9001b55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " relatorio de dados normalizados (382, 16)\n",
            "\n",
            "               precision    recall  f1-score     support\n",
            "BCC            0.714286  0.794393  0.752212  107.000000\n",
            "BCC ++         0.590909  0.393939  0.472727   66.000000\n",
            "BCC B2         0.617647  0.677419  0.646154   31.000000\n",
            "FCC            0.544304  0.693548  0.609929   62.000000\n",
            "FCC ++         0.688889  0.584906  0.632653   53.000000\n",
            "FCC BCC        0.488372  0.500000  0.494118   42.000000\n",
            "OTHER          0.444444  0.380952  0.410256   21.000000\n",
            "accuracy       0.615183  0.615183  0.615183    0.615183\n",
            "macro avg      0.584122  0.575023  0.574007  382.000000\n",
            "weighted avg   0.614342  0.615183  0.608461  382.000000 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "simple_forest = RandomForestClassifier(\n",
        "    max_depth=13,\n",
        "    random_state=54, \n",
        "    criterion='gini', \n",
        "    max_features='auto',\n",
        "    n_estimators = 195,\n",
        "    )\n",
        "\n",
        "microstructure_pred_droped_duplicates_normalized = cross_val_predict(\n",
        "    simple_forest, \n",
        "    properties_droped_duplicates_normalized, \n",
        "    microstructure_droped_duplicates.values.reshape(-1,), \n",
        "    cv=k_folds\n",
        "  )\n",
        "\n",
        "microstructure_confusion_matrix_droped_duplicates_normalized = \\\n",
        "  multilabel_confusion_matrix(\n",
        "      microstructure_droped_duplicates, \n",
        "      microstructure_pred_droped_duplicates_normalized\n",
        "  )\n",
        "\n",
        "clf_report_droped_duplicates_normalized = classification_report(\n",
        "    microstructure_droped_duplicates, \n",
        "    microstructure_pred_droped_duplicates_normalized,\n",
        "    output_dict=True\n",
        "  )\n",
        "\n",
        "# transform column index number to microstructure\n",
        "clf_report_droped_duplicates_normalized = {categorical_key(k):v for (k,v) in clf_report_droped_duplicates_normalized.items()}\n",
        "\n",
        "df_classification_report_droped_duplicates_normalized = pd.DataFrame(\n",
        "    clf_report_droped_duplicates_normalized\n",
        "  ).transpose()\n",
        "\n",
        "# df_classification_report.index.names = ['microstructure']\n",
        "\n",
        "cm_microstructure_droped_duplicates_normalized = confusion_matrix(\n",
        "      microstructure_droped_duplicates.values.reshape(-1,), \n",
        "      microstructure_pred_droped_duplicates_normalized\n",
        "  )\n",
        "\n",
        "\n",
        "print('\\n relatorio de dados normalizados', \n",
        "      properties_droped_duplicates_normalized.shape)\n",
        "print('\\n', df_classification_report_droped_duplicates_normalized, '\\n')\n",
        "make_confusion_matrix(cm_microstructure_droped_duplicates_normalized, \n",
        "                      figsize=(10,8), \n",
        "                      categories=microstructures,\n",
        "                      cmap='Reds',\n",
        "                      title='Dados normalizados')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados dos hiperparâmetros otimizados validando com cross validation do conjunto de treino"
      ],
      "metadata": {
        "id": "3sPzGs2-icOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized_forest = RandomForestClassifier(\n",
        "#     random_state=54,\n",
        "#     criterion='gini', max_depth=13, max_features='auto', n_estimators=200 )\n",
        "\n",
        "optimized_forest = RandomForestClassifier(\n",
        "    max_depth=13,\n",
        "    random_state=54, \n",
        "    criterion='gini', \n",
        "    max_features='auto',\n",
        "    n_estimators = 195,\n",
        "    )\n",
        "\n",
        "oversampled='KMeansSMOTE'\n",
        "\n",
        "\n",
        "model_name = str(optimized_forest.__class__.__name__)\n",
        "\n",
        "microstructure_pred_oversampled = cross_val_predict(\n",
        "    optimized_forest, \n",
        "    data_oversampled[oversampled]['properties_train_oversampled'], \n",
        "    data_oversampled[oversampled]['microstructure_train_oversampled'],\n",
        "    cv=10\n",
        "  )\n",
        "\n",
        "microstructure_confusion_matrix_oversampled = \\\n",
        "  confusion_matrix(\n",
        "      data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "      microstructure_pred_oversampled\n",
        "  )\n",
        "\n",
        "clf_report_oversampled = classification_report(\n",
        "    data_oversampled[oversampled]['microstructure_train_oversampled'], \n",
        "    microstructure_pred_oversampled,\n",
        "    output_dict=True\n",
        "  )\n",
        "\n",
        "f1_scores = []\n",
        "for i in clf_report_oversampled:\n",
        "  if is_float(i):\n",
        "    f1_scores.append(clf_report_oversampled[i]['f1-score'])\n",
        "\n",
        "# transform column index number to microstructure\n",
        "clf_report_oversampled = {categorical_key(k):v for (k,v) in clf_report_oversampled.items()}\n",
        "\n",
        "df_classification_report_oversampled = pd.DataFrame(\n",
        "    clf_report_oversampled\n",
        "  ).transpose()\n",
        "\n",
        "print(\"{0:30} {1:15} {2:30}\".format(oversampled, \n",
        "                              clf_report_oversampled['accuracy'], \n",
        "                              mean(f1_scores)))\n",
        "\n",
        "cm_microstructure_oversampled[oversampled] = \\\n",
        "  microstructure_confusion_matrix_oversampled\n",
        "\n",
        "print('\\n Model: ', model_name)\n",
        "print(df_classification_report_oversampled)"
      ],
      "metadata": {
        "id": "RfXTT8D-iK5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc2d064-8c8a-4fd5-c7a5-e48a30a50df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeansSMOTE                    0.8250950570342205              0.825584726547246\n",
            "\n",
            " Model:  RandomForestClassifier\n",
            "              precision    recall  f1-score     support\n",
            "BCC            0.750000  0.810811  0.779221   74.000000\n",
            "BCC ++         0.819444  0.776316  0.797297   76.000000\n",
            "BCC B2         0.870130  0.905405  0.887417   74.000000\n",
            "FCC            0.768293  0.828947  0.797468   76.000000\n",
            "FCC ++         0.847222  0.792208  0.818792   77.000000\n",
            "FCC BCC        0.847222  0.813333  0.829932   75.000000\n",
            "OTHER          0.887324  0.851351  0.868966   74.000000\n",
            "accuracy       0.825095  0.825095  0.825095    0.825095\n",
            "macro avg      0.827091  0.825482  0.825585  526.000000\n",
            "weighted avg   0.826991  0.825095  0.825340  526.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados dos hiperparâmetros otimizados validando com conjunto de teste"
      ],
      "metadata": {
        "id": "VnJbtDg6iLbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_forest = RandomForestClassifier(random_state=54)\n",
        "    # random_state=54,\n",
        "    # criterion='gini', max_depth=13, max_features='auto', n_estimators=200 )\n",
        "\n",
        "\n",
        "# optimized_forest = RandomForestClassifier(\n",
        "#     random_state=54,\n",
        "#     criterion='entropy', max_depth=5, max_features=None, n_estimators=500 )\n",
        "\n",
        "# Fitting 10 folds for each of 792 candidates, totalling 7920 fits\n",
        "# {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'n_estimators': 500}\n",
        "\n",
        "oversampled='KMeansSMOTE'\n",
        "model_name = optimized_forest.__class__.__name__\n",
        "\n",
        "homolog_fit = optimized_forest.fit(\n",
        "        data_oversampled[oversampled]['properties_train_oversampled'], \n",
        "        data_oversampled[oversampled]['microstructure_train_oversampled']\n",
        "        )\n",
        "\n",
        "caracteristic_homolog_pred = homolog_fit.predict(x_test_normalized)\n",
        "\n",
        "clf_report_oversampled_homolog = classification_report(\n",
        "    y_test_normalized, \n",
        "    caracteristic_homolog_pred,\n",
        "    output_dict=True\n",
        "  )\n",
        "\n",
        "f1_scores = []\n",
        "for i in clf_report_oversampled_homolog:\n",
        "  if is_float(i):\n",
        "    f1_scores.append(clf_report_oversampled_homolog[i]['f1-score'])\n",
        "\n",
        "# transform column index number to microstructure\n",
        "clf_report_oversampled_homolog = {categorical_key(k):v for (k,v) in clf_report_oversampled_homolog.items()}\n",
        "\n",
        "df_classification_report_oversampled_homolog = pd.DataFrame(\n",
        "    clf_report_oversampled_homolog\n",
        "  ).transpose()\n",
        "\n",
        "\n",
        "print(\"{0:30} {1:15} {2:30}\".format(oversampled, \n",
        "                              clf_report_oversampled_homolog['accuracy'], \n",
        "                              mean(f1_scores)))\n",
        "\n",
        "cm_microstructure_oversampled_homolog[oversampled] = confusion_matrix(\n",
        "    y_test_droped_duplicates, \n",
        "    caracteristic_homolog_pred,\n",
        ")\n",
        "\n",
        "print('\\n Model: ', model_name)\n",
        "print(df_classification_report_oversampled_homolog)"
      ],
      "metadata": {
        "id": "1-F5pBqJc6Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def rd(n, total_sum):\n",
        "    nums = np.random.rand(n)\n",
        "    return nums/np.sum(nums)*total_sum\n",
        "\n",
        "n = rd(16,1)\n",
        "\n"
      ],
      "metadata": {
        "id": "ycvHGy57wsDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4Zd6ZaQli7hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n_elements = random.randint(3, 5)\n",
        "# composition = rd(n_elements,1)\n",
        "\n",
        "my_list = list([i for i in range(16)])\n",
        "random.shuffle(my_list)\n",
        "\n",
        "print(my_list)\n",
        "print(my_list[random.randint(0, 15)])"
      ],
      "metadata": {
        "id": "jcYQfVsniz6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_teste = pd.DataFrame([n], columns=properties_droped_duplicates.columns)\n",
        "\n",
        "my_list = list([i for i in range(16)])\n",
        "\n",
        "for i in range(500):\n",
        "\n",
        "  n_elements = random.randint(3, 5)\n",
        "  composition = rd(n_elements,1)\n",
        "\n",
        "  composition_final = [0] * 16\n",
        "  \n",
        "  random.shuffle(my_list)\n",
        "\n",
        "  for j in composition:\n",
        "    composition_final[my_list[random.randint(0, 15)]] = j\n",
        "    \n",
        "\n",
        "\n",
        "  new_row = pd.Series(composition_final, index = df_teste.columns)\n",
        "  df_teste = df_teste.append(new_row, ignore_index=True)\n",
        "\n",
        "print(df_teste)"
      ],
      "metadata": {
        "id": "b7O5Usq6x03q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caracteristic_teste_predict[1]"
      ],
      "metadata": {
        "id": "bClmCawzoXDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# caracteristic_teste_predict = homolog_fit.predict(x_test_normalized)\n",
        "\n",
        "caracteristic_teste_predict = homolog_fit.predict(df_teste)\n",
        "print(caracteristic_teste_predict)\n",
        "\n",
        "micros_teste = [microstructure_ord_enc.inverse_transform([[k]])[0][0] for k in caracteristic_teste_predict]\n",
        "\n",
        "print(micros_teste)\n",
        "# x_test_normalized\n",
        "# df_teste"
      ],
      "metadata": {
        "id": "vdMGy9KNcWYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(caracteristic_teste_predict)\n",
        "print(x_test_normalized)"
      ],
      "metadata": {
        "id": "vmOqg3ZshUbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Analise HEAs",
      "provenance": [],
      "mount_file_id": "1SWuTjAW29qzwQx30y56PGuFDgPJOzdjl",
      "authorship_tag": "ABX9TyOKdtlpOaKeUc8ZNCrX4fZ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}